{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据探索与可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/distracted_driver_detection/imgs 已存在\n"
     ]
    }
   ],
   "source": [
    "#解压imgs.zip文件\n",
    "import zipfile\n",
    "from os.path import isfile, isdir\n",
    "\n",
    "imgs_path = '/home/ubuntu/distracted_driver_detection/imgs'\n",
    "zip_path = '/home/ubuntu/distracted_driver_detection/imgs.zip'\n",
    "\n",
    "if not isdir(imgs_path):\n",
    "    file = zipfile.ZipFile(zip_path, 'r')\n",
    "    file.extractall(imgs_path)\n",
    "    file.close()\n",
    "    print(\"解压已完成\")\n",
    "else:\n",
    "    print(imgs_path + \" 已存在\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 检测csv文件中的测试图片是否与测试集(Train set)中图片相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The describe of driver_imgs_list: \n",
      "       subject classname            img\n",
      "count    22424     22424          22424\n",
      "unique      26        10          22424\n",
      "top       p021        c0  img_10647.jpg\n",
      "freq      1237      2489              1\n",
      "\n",
      "CSV文件与Train数据集完全匹配，共22424张训练照片\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "csv_path = '/home/ubuntu/distracted_driver_detection/driver_imgs_list.csv'\n",
    "\n",
    "imgs = pd.read_csv(csv_path)\n",
    "miss = []\n",
    "\n",
    "print(\"The describe of driver_imgs_list: \")\n",
    "print(imgs.describe())\n",
    "print()\n",
    "\n",
    "count = imgs.shape[0]\n",
    "for i in range(count):\n",
    "    driver_status = imgs.iloc[i]['classname']\n",
    "    image = imgs.iloc[i]['img']\n",
    "    imgs_path = os.path.join('/home/ubuntu/distracted_driver_detection/imgs/train', driver_status, image)\n",
    "    \n",
    "    if not os.path.exists(imgs_path):\n",
    "        miss.append(imgs_path)\n",
    "        \n",
    "if len(miss) == 0:\n",
    "    print(\"CSV文件与Train数据集完全匹配，共{}张训练照片\".format(count))\n",
    "else:\n",
    "    print(\"有缺失文件：\")\n",
    "    print(miss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从describe信息中我们可以得知，共有26个驾驶员，10个驾驶状态，22424张照片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The describe of driver_imgs_list: \n",
      "       subject classname            img\n",
      "count    22424     22424          22424\n",
      "unique      26        10          22424\n",
      "top       p021        c0  img_10647.jpg\n",
      "freq      1237      2489              1\n",
      "<class 'numpy.ndarray'>\n",
      "There are 26 drivers.\n",
      "['p002' 'p012' 'p014' 'p015' 'p016' 'p021' 'p022' 'p024' 'p026' 'p035'\n",
      " 'p039' 'p041' 'p042' 'p045' 'p047' 'p049' 'p050' 'p051' 'p052' 'p056'\n",
      " 'p061' 'p064' 'p066' 'p072' 'p075' 'p081']\n"
     ]
    }
   ],
   "source": [
    "imgs = pd.read_csv(csv_path)\n",
    "\n",
    "print(\"The describe of driver_imgs_list: \")\n",
    "print(imgs.describe())\n",
    "\n",
    "drivers = np.unique(imgs['subject'])\n",
    "print(type(drivers))\n",
    "print('There are {} drivers.'.format(drivers.size))\n",
    "print(drivers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 26 drivers.\n",
      "['p002' 'p012' 'p014' 'p015' 'p016' 'p021' 'p022' 'p024' 'p026' 'p035'\n",
      " 'p039' 'p041' 'p042' 'p045' 'p047' 'p049' 'p050' 'p051' 'p052' 'p056'\n",
      " 'p061' 'p064' 'p066' 'p072' 'p075' 'p081']\n",
      "There are 10 classes.\n",
      "['c0' 'c1' 'c2' 'c3' 'c4' 'c5' 'c6' 'c7' 'c8' 'c9']\n",
      "   drivers   c0   c1   c2   c3   c4   c5   c6   c7   c8   c9\n",
      "0     p002   76   74   86   79   84   76   83   72   44   51\n",
      "1     p012   84   95   91   89   97   96   75   72   62   62\n",
      "2     p014  100  103  100  100  103  102  101   77   38   52\n",
      "3     p015   79   85   88   94  101  101   99   81   86   61\n",
      "4     p016  111  102  101  128  104  104  108  101   99  120\n",
      "5     p021  135  131  127  128  132  130  126   98   99  131\n",
      "6     p022  129  129  128  129  130  130  131   98   98  131\n",
      "7     p024  130  129  128  130  129  131  129  101   99  120\n",
      "8     p026  130  129  130  131  126  130  128   97   97   98\n",
      "9     p035   94   81   88   89   89   89   94   87   56   81\n",
      "10    p039   65   63   70   65   62   64   63   64   70   65\n",
      "11    p041   60   64   60   60   60   61   61   61   59   59\n",
      "12    p042   59   59   60   59   58   59   59   59   59   60\n",
      "13    p045   75   75   76   75   75   76   71   67   66   68\n",
      "14    p047   80   91   81   86   82   87   81   82   82   83\n",
      "15    p049   84   85  119  110  109  116  119   74   79  116\n",
      "16    p050  123   45   52   98   83   91   82   81   65   70\n",
      "17    p051  182   81   81   83   81   83   95   80   62   92\n",
      "18    p052   72   71   84   75   72   72   77   71   71   75\n",
      "19    p056   81   80   80   78   82   81   80   74   83   75\n",
      "20    p061   84   81   81   83   79   81   80   79   81   80\n",
      "21    p064   83   81   83   84   86   85   82   79   81   76\n",
      "22    p066  129  100  106  101  102  101  105   86  114   90\n",
      "23    p072   63   62   36   31   34    6   35    2   21   56\n",
      "24    p075   81   81   85   79   89   79   82   82   79   77\n",
      "25    p081  100   90   96   82   77   81   79   77   61   80\n"
     ]
    }
   ],
   "source": [
    "#统计测试集中驾驶员数量\n",
    "drivers = np.unique(imgs['subject'])\n",
    "print('There are {} drivers.'.format(len(drivers)))\n",
    "print(drivers)\n",
    "\n",
    "#统计测试集中安全状态数量\n",
    "safety_status = np.unique(imgs['classname'])\n",
    "print('There are {} classes.'.format(len(safety_status)))\n",
    "print(safety_status)\n",
    "\n",
    "columns = ['drivers'] + list(safety_status)\n",
    "\n",
    "df = list()\n",
    "for driver in drivers:\n",
    "    row = [driver]\n",
    "    for ss in safety_status:\n",
    "        #技巧，list[(条件1) & (条件2)]\n",
    "        num = len(imgs[(imgs['subject']==driver) & (imgs['classname']==ss)])\n",
    "        row.append(num)\n",
    "    df.append(row)    \n",
    "\n",
    "df = pd.DataFrame(df, columns=columns)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pandas/plotting/_core.py:1716: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  series.name = label\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "with sns.color_palette(palette=\"RdBu\", n_colors=10):\n",
    "    df.plot.bar(x=drivers, y=safety_status, stacked=True, figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** start code 参考来自 https://www.kaggle.com/zfturbo/keras-sample/code **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** get_im函数以path读入image图片信息，并改其大小 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image    \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#根据第三次review的建议，如果使用以imagenet为权重的预训练模型VGG16，建议align imagenet的预处理方法\n",
    "#所以RGB->BGR, 然后减均值.\n",
    "def get_im(path, img_rows=224, img_cols=224, color_type=3):\n",
    "    \n",
    "    #read the image\n",
    "    img = image.load_img(path, target_size=(img_rows, img_cols))\n",
    "    \n",
    "    #image to array\n",
    "    x = image.img_to_array(img)\n",
    "    \n",
    "    # RGB >> BGR\n",
    "    x = x[:, :, ::-1]\n",
    "    \n",
    "    # Zero-center by mean pixel\n",
    "    x[:, :, 0] -= 103.939\n",
    "    x[:, :, 1] -= 116.779\n",
    "    x[:, :, 2] -= 123.68\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "** get_driver_data函数读取driver_imgs_list.csv文件，csv有三列(subject,classname,img), 以字典形式返回** <br>\n",
    "(1) dr，key为img, value为图片对应的subject信息；\n",
    "(2) subj, key为subject, value为(classname, img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_driver_data():\n",
    "    dr = dict()\n",
    "    subj = dict()\n",
    "    print('Read drivers data')\n",
    "    \n",
    "    # 使用没有经过ROI处理的train图像集\n",
    "    #f = open('/home/ubuntu/distracted_driver_detection/driver_imgs_list.csv', 'r')\n",
    "    \n",
    "    # 使用经过ROI处理的train图像集\n",
    "    f = open('/home/ubuntu/distracted_driver_detection/driver_imgs_list_roi.csv', 'r')\n",
    "    line = f.readline()\n",
    "    \n",
    "    while (1):\n",
    "        line = f.readline()\n",
    "        if line == '':\n",
    "            break\n",
    "        arr = line.strip().split(',')\n",
    "        dr[arr[2]] = arr[0]\n",
    "    \n",
    "        if arr[0] not in subj.keys():\n",
    "            subj[arr[0]] = [(arr[1], arr[2])]\n",
    "        else:\n",
    "            subj[arr[0]].append((arr[1], arr[2]))\n",
    "            \n",
    "    f.close()\n",
    "    \n",
    "    return dr, subj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** generate_driver_imgs_list_roi()函数 ** <br>\n",
    "把driver_imgs_list.csv文件中第三列的所有文件名，加上“ROI”标识，如：\n",
    "“p002,c0,img_44733.jpg”改为\"p002,c0,img_44733_ROI.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_driver_imgs_list_roi():\n",
    "    f = open('/home/ubuntu/distracted_driver_detection/driver_imgs_list.csv', 'r')\n",
    "    with open('/home/ubuntu/distracted_driver_detection/driver_imgs_list_roi.csv', 'w') as filehandle:\n",
    "        for eachline in f:\n",
    "            x = eachline.strip().split('.')\n",
    "            if len(x) == 1:\n",
    "                filehandle.write('%s\\n' % x[0])\n",
    "            else:\n",
    "                x = x[0] + \"_ROI.\"+x[1]\n",
    "                filehandle.write('%s\\n' % x)\n",
    "    filehandle.close()\n",
    "    f.close()\n",
    "    \n",
    "#generate_driver_imgs_list_roi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** load_train函数导入train图片 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train(img_rows=224, img_cols=224, color_type=3):\n",
    "    import glob\n",
    "    \n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    driver_id = []\n",
    "    driver_file_id=[]\n",
    "    unique_drivers = []\n",
    "\n",
    "    driver_data, dr_class = get_driver_data()\n",
    "    \n",
    "    print('Read Train images')\n",
    "    for j in range(10):\n",
    "        print('Load folder c{}'.format(j))\n",
    "        \n",
    "        #使用未经过ROI处理过的train数据集\n",
    "        #path = os.path.join('/home/ubuntu/distracted_driver_detection/imgs', \n",
    "        #                    'train', 'c' + str(j), '*.jpg')\n",
    "        \n",
    "        # 使用经过ROI处理过的train数据集\n",
    "        path = os.path.join('/home/ubuntu/distracted_driver_detection/imgs', \n",
    "                            'train', 'c' + str(j), '*ROI.jpg')\n",
    "        files = glob.glob(path)\n",
    "        \n",
    "        #files = glob(path)\n",
    "        print('The number of jpg files of c{} folder:{}'.format(j, len(files)))\n",
    "        \n",
    "        for fl in files:\n",
    "            filename = os.path.basename(fl)\n",
    "            img = get_im(fl, img_rows, img_cols, color_type)\n",
    "            \n",
    "            X_train.append(img)\n",
    "            y_train.append(j)\n",
    "            driver_file_id.append(filename)\n",
    "            \n",
    "            driver_id.append(driver_data[filename])\n",
    "\n",
    "    unique_drivers = sorted(list(set(driver_id)))\n",
    "    print('Unique drivers: {}'.format(len(unique_drivers)))\n",
    "    print(unique_drivers)\n",
    "    \n",
    "    return X_train, y_train, driver_file_id, driver_id, unique_drivers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 定义cache_data与restore_data函数 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saves data into a dump file, in the specified path \n",
    "def cache_data(data, path):\n",
    "    if not os.path.isdir('cache'):\n",
    "        os.mkdir('cache')\n",
    "        \n",
    "    if os.path.isdir(os.path.dirname(path)):\n",
    "        file = open(path, 'wb')\n",
    "        pickle.dump(data, file)\n",
    "        file.close()\n",
    "    else:\n",
    "        print('cache directory does not exist')\n",
    "\n",
    "#Loads data from cache file\n",
    "def restore_data(path):\n",
    "    data = dict()\n",
    "    if os.path.isfile(path):\n",
    "        print('Restore data from pickle......')\n",
    "        file = open(path, 'rb')\n",
    "        data = pickle.load(file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 定义read_and_normalize_train_data函数, normalize方法：除255.0 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "def read_and_normalize_train_data(img_rows=224, img_cols=224 , color_type=3):\n",
    "\n",
    "    train_data, train_target, train_id, driver_id, unique_drivers = load_train(img_rows, img_cols, color_type)\n",
    "    \n",
    "    train_data = np.array(train_data, dtype=np.float16)\n",
    "    \n",
    "    #normalize\n",
    "    train_data = train_data / 255.0  \n",
    "    \n",
    "    #no_one_hot\n",
    "    train_target = np.array(train_target, dtype=np.uint8)  \n",
    "    \n",
    "    return train_data, train_target, train_id, driver_id, unique_drivers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 定义辅助函数 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.callbacks import *\n",
    "\n",
    "import datetime\n",
    "import gc\n",
    "\n",
    "def dict_to_list(d):\n",
    "    ret = []\n",
    "    for i in d.items():\n",
    "        ret.append(i[1])  \n",
    "    return ret\n",
    "\n",
    "def merge_several_folds_mean(data, nfolds):\n",
    "    a = np.array(data[0])\n",
    "    for i in range(1, nfolds):\n",
    "        a += np.array(data[i])\n",
    "    a /= nfolds  \n",
    "    return a.tolist()\n",
    "\n",
    "# Copy the selected drivers data and labels into np.arrays\n",
    "def copy_selected_drivers(train_data, train_target, driver_id, driver_list, test=False):\n",
    "    data = []\n",
    "    target = []\n",
    "    index = []\n",
    "    \n",
    "    for i in range(len(driver_id)):\n",
    "        if driver_id[i] in driver_list:\n",
    "            data.append(train_data[i])\n",
    "            target.append(train_target[i])\n",
    "            index.append(i)\n",
    "    \n",
    "    data = np.array(data, dtype=np.float32)\n",
    "    target = np.array(target, dtype=np.uint8)\n",
    "    index = np.array(index, dtype=np.uint32)\n",
    "    \n",
    "    if test == True:\n",
    "        return data, target, index\n",
    "    else:\n",
    "        return data, target\n",
    "    \n",
    "\n",
    "from keras.callbacks import Callback\n",
    "# Visualize the train and validation loss plot\n",
    "# Refer to https://github.com/jartantupjar/7-Distracted-Driver-Detection/blob/master/\n",
    "#                  Solution%203%20-%20K-fold%20Implementation.ipynb\n",
    "class PlotLosses(Callback):\n",
    "    \n",
    "    # Initializes plot on first epoch\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.logs = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.fig = plt.figure()\n",
    "        \n",
    "        \n",
    "    # Prints a plot at the end of each epoch\n",
    "    def on_epoch_end(self, epoch, logs={}):  \n",
    "        self.logs.append(logs)\n",
    "        self.x.append(self.i)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.i += 1\n",
    "        \n",
    "        plt.plot(self.x, self.losses, label=\"loss\")\n",
    "        plt.plot(self.x, self.val_losses, label=\"val_loss\")\n",
    "        plt.legend(['train', 'test'], loc='upper left')\n",
    "        plt.show();\n",
    "        \n",
    "def collect_and_show_garbage():\n",
    "    print(\"Start to collect and clear garbage memory.\")\n",
    "    print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    n = gc.collect()\n",
    "    gc.garbage\n",
    "    print('unreachle objects:', n)\n",
    "    print(gc.garbage)\n",
    "    print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    print(\"End to collect and clear garbage memory.\")\n",
    "\n",
    "class MemoryCallback(Callback):\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        collect_and_show_garbage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建VGG16模型\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 迁移学习VGG16模型的参数，权重使用imgenet **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG16_arch(img_rows, img_cols, img_channel, a):\n",
    "    \n",
    "    #Calls the Keras application model with pre trained weights\n",
    "    base_model = VGG16(input_shape=(img_rows, img_cols, img_channel),\n",
    "                       weights='imagenet', include_top=False)\n",
    "\n",
    "    x = base_model.output\n",
    "    \n",
    "    #Additional model layers\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    predictions = Dense(10, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    for layer in model.layers[a:]:\n",
    "        layer.trainable = True    \n",
    "    model.compile(optimizer=Adam(lr=1e-4), loss='categorical_crossentropy')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**函数load_pseudo_train(), read_and_normalize_pseudo_train_data(), add_pseudo_train_data_from_test_set()均是对pseudo sample的处理**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pickle\n",
    "\n",
    "def load_pseudo_train(img_rows=224, img_cols=224, color_type=3, use_roi_picture = True, pseudo_number = 8000):\n",
    "    import random\n",
    "    \n",
    "    pseudo_X_train = []\n",
    "    pseudo_y_train = []\n",
    "    \n",
    "    pseudo_data = restore_data(\"/home/ubuntu/distracted_driver_detection/testset_result.pkl\")\n",
    "    prefix_path = ''\n",
    "    \n",
    "    for class_name, imgs_list in pseudo_data.items():\n",
    "        \n",
    "        #random select the data from every driver status\n",
    "        imgs_list = random.sample(imgs_list, int(pseudo_number/10.0))\n",
    "        \n",
    "        # add code: translate the img name to img_roi name, if the use_roi_picture = True\n",
    "        if use_roi_picture == True:\n",
    "            prefix_path = '/home/ubuntu/distracted_driver_detection/imgs/test_roi'\n",
    "            for i in range(len(imgs_list)):\n",
    "                filename = imgs_list[i]\n",
    "                f = filename.split(\".\")\n",
    "                imgs_list[i] = f[0]+\"_\"+\"ROI\"+\".\"+f[1]\n",
    "        else: \n",
    "            prefix_path = '/home/ubuntu/distracted_driver_detection/imgs/test'\n",
    "            \n",
    "        for img in imgs_list:\n",
    "            path = os.path.join(prefix_path, img)\n",
    "            img = get_im(path, img_rows, img_cols, color_type)\n",
    "            pseudo_X_train.append(img)\n",
    "            pseudo_y_train.append(class_name)\n",
    "            \n",
    "    print(\"load_pseudo_train Done\")\n",
    "    return pseudo_X_train, pseudo_y_train\n",
    "\n",
    "\n",
    "def read_and_normalize_pseudo_train_data(img_rows=224, img_cols=224, color_type=3, \n",
    "                                         use_roi_picture = True, pseudo_number = 8000):\n",
    "    \n",
    "    pseudo_train_data, pseudo_train_target = load_pseudo_train(img_rows, img_cols, color_type, \n",
    "                                                                use_roi_picture, pseudo_number)\n",
    "        \n",
    "    pseudo_train_data = np.array(pseudo_train_data, dtype=np.float16)\n",
    "    pseudo_train_data = pseudo_train_data / 255.0  #zero-center\n",
    "    \n",
    "    pseudo_train_target = np.array(pseudo_train_target, dtype=np.uint8)  #no_one_hot\n",
    "    \n",
    "    print('Read_and_normalize_pseudo_train_data Done')\n",
    "    return pseudo_train_data, pseudo_train_target\n",
    "\n",
    "\n",
    "def add_pseudo_train_data_from_test_set(X_train, Y_train, use_roi_picture = True, pseudo_number = 8000):\n",
    "    pseudo_X_train, pseudo_Y_train = read_and_normalize_pseudo_train_data(\n",
    "        224, 224, 3, use_roi_picture, pseudo_number)\n",
    "    \n",
    "    #return X_train.extend(pseudo_X_train), Y_train.extend(pseudo_Y_train)\n",
    "    return np.concatenate([X_train, pseudo_X_train]), np.concatenate([Y_train, pseudo_Y_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VGG16模型参数准备**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图片处理为244*244，是为了适应VGG16模型要求\n",
    "img_rows=224\n",
    "img_cols=224\n",
    "img_channel=3  \n",
    "\n",
    "nfolds=7\n",
    "epochs=10\n",
    "batch_size=32\n",
    "use_pseudo_train_data = True\n",
    "use_roi_picture = True\n",
    "pseudo_number = 8000\n",
    "freezing_layer = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练VGG16模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read drivers data\n",
      "Read Train images\n",
      "Load folder c0\n",
      "The number of jpg files of c0 folder:2489\n",
      "Load folder c1\n",
      "The number of jpg files of c1 folder:2267\n",
      "Load folder c2\n",
      "The number of jpg files of c2 folder:2317\n",
      "Load folder c3\n",
      "The number of jpg files of c3 folder:2346\n",
      "Load folder c4\n",
      "The number of jpg files of c4 folder:2326\n",
      "Load folder c5\n",
      "The number of jpg files of c5 folder:2312\n",
      "Load folder c6\n",
      "The number of jpg files of c6 folder:2325\n",
      "Load folder c7\n",
      "The number of jpg files of c7 folder:2002\n",
      "Load folder c8\n",
      "The number of jpg files of c8 folder:1911\n",
      "Load folder c9\n",
      "The number of jpg files of c9 folder:2129\n",
      "Unique drivers: 26\n",
      "['p002', 'p012', 'p014', 'p015', 'p016', 'p021', 'p022', 'p024', 'p026', 'p035', 'p039', 'p041', 'p042', 'p045', 'p047', 'p049', 'p050', 'p051', 'p052', 'p056', 'p061', 'p064', 'p066', 'p072', 'p075', 'p081']\n",
      "Use_pseudo_train_data\n",
      "Restore data from pickle......\n",
      "load_pseudo_train Done\n",
      "Read_and_normalize_pseudo_train_data Done\n",
      "Start KFold number 1 of 7\n",
      "2018-08-30 07:22:20\n",
      "Train drivers:['p002', 'p012', 'p014', 'p015', 'p016', 'p021', 'p022', 'p035', 'p041', 'p042', 'p045', 'p047', 'p049', 'p050', 'p051', 'p052', 'p056', 'p061', 'p064', 'p066', 'p075', 'p081'], Test drivers:['p024', 'p026', 'p039', 'p072']\n",
      "Score accuracy_score:  0.9502778590231061\n",
      "[[356   6   0   0   0   0   0   0   7  19]\n",
      " [  0 382   0   0   0   0   0   0   0   1]\n",
      " [  0   0 325   0   0   0   0   0  39   0]\n",
      " [ 14   0   0 335   0   0   0   0   1   7]\n",
      " [  0   0   0   2 349   0   0   0   0   0]\n",
      " [  1   0   0   0   0 330   0   0   0   0]\n",
      " [  0   2   0   0   0   0 340   0  13   0]\n",
      " [  0   0   0   0   1   0   0 263   0   0]\n",
      " [  8   1   1   0   0   0   1   1 274   1]\n",
      " [ 37   0   0   0   3   3   0   0   1 295]]\n",
      "Score log_loss:  0.17328886596258297\n",
      "Use_pseudo_train_data\n",
      "Restore data from pickle......\n",
      "load_pseudo_train Done\n",
      "Read_and_normalize_pseudo_train_data Done\n",
      "Start KFold number 2 of 7\n",
      "2018-08-30 07:24:37\n",
      "Train drivers:['p002', 'p015', 'p016', 'p021', 'p022', 'p024', 'p026', 'p035', 'p039', 'p041', 'p042', 'p045', 'p047', 'p049', 'p050', 'p051', 'p052', 'p064', 'p066', 'p072', 'p075', 'p081'], Test drivers:['p012', 'p014', 'p056', 'p061']\n",
      "Score accuracy_score:  0.9103573591762568\n",
      "[[327   0   0   0   1   0   0   0   1  20]\n",
      " [  1 344   0   0   0   0   0   0  12   2]\n",
      " [  0   2 341   0   0   0   1   0   8   0]\n",
      " [ 22   0   0 326   2   0   0   0   0   0]\n",
      " [  0   0   0   1 359   0   1   0   0   0]\n",
      " [  3   0   0   0   0 357   0   0   0   0]\n",
      " [  0   6   0   0   0   2 297   0  27   4]\n",
      " [  0   0   0   0   0   1   0 292   1   8]\n",
      " [ 13   0   0   2  22   0   5  28 178  16]\n",
      " [ 77   0   0   1   0   0   0   0   6 185]]\n",
      "Score log_loss:  0.28775123452119755\n",
      "Use_pseudo_train_data\n",
      "Restore data from pickle......\n",
      "load_pseudo_train Done\n",
      "Read_and_normalize_pseudo_train_data Done\n",
      "Start KFold number 3 of 7\n",
      "2018-08-30 07:26:48\n",
      "Train drivers:['p002', 'p012', 'p014', 'p016', 'p021', 'p024', 'p026', 'p035', 'p039', 'p042', 'p047', 'p049', 'p050', 'p051', 'p052', 'p056', 'p061', 'p064', 'p066', 'p072', 'p075', 'p081'], Test drivers:['p015', 'p022', 'p041', 'p045']\n",
      "Score accuracy_score:  0.9586848996217632\n",
      "[[317   0   0   0   0   0   0   0  13  13]\n",
      " [  6 347   0   0   0   0   0   0   0   0]\n",
      " [  0   0 342   0   0   0   0   0  10   0]\n",
      " [  0   0   0 358   0   0   0   0   0   0]\n",
      " [  0   0   0   0 360   0   0   0   6   0]\n",
      " [  0   1   1   0   1 353   0   0   3   9]\n",
      " [  0   0   0   0   0   0 353   0   9   0]\n",
      " [  0   0   0   0   0   0   0 307   0   0]\n",
      " [  0   2   2   0   0   0  18   0 287   0]\n",
      " [ 38   0   0   0   0   6   0   0   4 271]]\n",
      "Score log_loss:  0.15942442468966941\n",
      "Use_pseudo_train_data\n",
      "Restore data from pickle......\n",
      "load_pseudo_train Done\n",
      "Read_and_normalize_pseudo_train_data Done\n",
      "Start KFold number 4 of 7\n",
      "2018-08-30 07:29:00\n",
      "Train drivers:['p002', 'p012', 'p014', 'p015', 'p021', 'p022', 'p024', 'p026', 'p035', 'p039', 'p041', 'p045', 'p047', 'p050', 'p052', 'p056', 'p061', 'p064', 'p066', 'p072', 'p075', 'p081'], Test drivers:['p016', 'p042', 'p049', 'p051']\n",
      "Score accuracy_score:  0.9819444444444444\n",
      "[[401   1   0   0   0   0   0   0  10  24]\n",
      " [  0 327   0   0   0   0   0   0   0   0]\n",
      " [  0   0 361   0   0   0   0   0   0   0]\n",
      " [  0   0   0 374   6   0   0   0   0   0]\n",
      " [  0   0   0   0 352   0   0   0   0   0]\n",
      " [  2   0   0   0   0 357   0   0   0   3]\n",
      " [  0   0   0   0   0   0 379   0   1   1]\n",
      " [  0   0   0   0   0   0   0 313   1   0]\n",
      " [  2   1   1   0   0   2   6   0 286   1]\n",
      " [  2   0   0   0   0   0   0   0   1 385]]\n",
      "Score log_loss:  0.0768067412470244\n",
      "Use_pseudo_train_data\n",
      "Restore data from pickle......\n",
      "load_pseudo_train Done\n",
      "Read_and_normalize_pseudo_train_data Done\n",
      "Start KFold number 5 of 7\n",
      "2018-08-30 07:31:15\n",
      "Train drivers:['p002', 'p012', 'p014', 'p015', 'p016', 'p021', 'p022', 'p024', 'p026', 'p035', 'p039', 'p041', 'p042', 'p045', 'p049', 'p050', 'p051', 'p056', 'p061', 'p072', 'p075', 'p081'], Test drivers:['p047', 'p052', 'p064', 'p066']\n",
      "Score accuracy_score:  0.9340915718868474\n",
      "[[345   0   0   0   0   3   0   0   0  16]\n",
      " [  0 340   0   0   0   0   0   2   0   1]\n",
      " [  0   0 345   0   0   0   0   1   8   0]\n",
      " [ 11   0   0 335   0   0   0   0   0   0]\n",
      " [  3   0   0   2 336   0   0   0   1   0]\n",
      " [ 14   0   0   0   0 330   0   0   0   1]\n",
      " [  0   3   1   0   0   0 332   0   9   0]\n",
      " [  1   1   0   0   0   0   0 311   1   4]\n",
      " [  0   9   9   0   4   0   5  23 289   9]\n",
      " [ 43   1   1   0   0  11   1   3  24 240]]\n",
      "Score log_loss:  0.25205739187296405\n",
      "Use_pseudo_train_data\n",
      "Restore data from pickle......\n",
      "load_pseudo_train Done\n",
      "Read_and_normalize_pseudo_train_data Done\n",
      "Start KFold number 6 of 7\n",
      "2018-08-30 07:33:27\n",
      "Train drivers:['p002', 'p012', 'p014', 'p015', 'p016', 'p021', 'p022', 'p024', 'p026', 'p039', 'p041', 'p042', 'p045', 'p047', 'p049', 'p051', 'p052', 'p056', 'p061', 'p064', 'p066', 'p072', 'p081'], Test drivers:['p035', 'p050', 'p075']\n",
      "Score accuracy_score:  0.9327079934747146\n",
      "[[274   0   0   0   0   8   0   0   1  15]\n",
      " [  0 203   0   3   0   0   1   0   0   0]\n",
      " [  0   0 203   0   0   0   0   0  22   0]\n",
      " [  0   0   0 262   0   0   0   0   4   0]\n",
      " [  1   0   0   5 249   0   0   0   6   0]\n",
      " [  5   0   0   0   0 254   0   0   0   0]\n",
      " [  2   0   0   0   0   0 256   0   0   0]\n",
      " [  0   0   0   0   0   1   0 249   0   0]\n",
      " [ 17   0   0   0   0   3   0   0 171   9]\n",
      " [ 40   3   0   1   0  16   0   0   2 166]]\n",
      "Score log_loss:  0.20033607819937477\n",
      "Use_pseudo_train_data\n",
      "Restore data from pickle......\n",
      "load_pseudo_train Done\n",
      "Read_and_normalize_pseudo_train_data Done\n",
      "Start KFold number 7 of 7\n",
      "2018-08-30 07:35:32\n",
      "Train drivers:['p012', 'p014', 'p015', 'p016', 'p022', 'p024', 'p026', 'p035', 'p039', 'p041', 'p042', 'p045', 'p047', 'p049', 'p050', 'p051', 'p052', 'p056', 'p061', 'p064', 'p066', 'p072', 'p075'], Test drivers:['p002', 'p021', 'p081']\n",
      "Score accuracy_score:  0.9353680430879713\n",
      "[[287   1   0   0   0   0   0   0   6  17]\n",
      " [  4 283   0   0   0   0   2   0   2   4]\n",
      " [  3   0 289   0   0   1   0   0   7   9]\n",
      " [  4   0   0 285   0   0   0   0   0   0]\n",
      " [  0   0   0   0 290   0   0   0   3   0]\n",
      " [  4   0   0   0   0 281   0   0   2   0]\n",
      " [  0   1   1   0   0   0 281   0   5   0]\n",
      " [  0   0   1   0   0   0   1 242   3   0]\n",
      " [ 10   0   4   0   6   0   3   0 178   3]\n",
      " [ 48   0   0   0   0   0   0   2  23 189]]\n",
      "Score log_loss:  0.24540785801708173\n",
      "Validation Average Score  0.199296084929985\n",
      "(validation score) Final log_loss: 13.388518827226868, nfolds: 7 epoch: 10\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "import cv2\n",
    "import math\n",
    "import pickle\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "#from PIL import ImageFile \n",
    "#ImageFile.LOAD_TRUNCATED_IMAGES = True \n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.metrics import log_loss, accuracy_score, confusion_matrix\n",
    "from sklearn.datasets import load_files\n",
    "from keras import optimizers\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import GlobalMaxPooling2D, Dense, Input\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.preprocessing import image    \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping, Callback, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "def build_VGG16_model(nfolds, epochs, batch_size, img_rows, img_cols, img_channel):\n",
    "    \n",
    "    train_files, train_targets, train_id, driver_id, unique_drivers = \\\n",
    "    read_and_normalize_train_data(img_rows=img_rows, img_cols=img_cols, color_type=img_channel)\n",
    "    \n",
    "    val_predictions = dict()\n",
    "    val_score=[]\n",
    "    \n",
    "    kf = KFold(n_splits=nfolds, shuffle=True, random_state=51)\n",
    "    num_fold = 0\n",
    "    \n",
    "    for train_drivers, valid_drivers in kf.split(unique_drivers):\n",
    "        gc.collect()\n",
    "        gc.garbage\n",
    "            \n",
    "        unique_list_train = [unique_drivers[i] for i in train_drivers]\n",
    "        X_train, Y_train = copy_selected_drivers(train_files, train_targets, \n",
    "                                                 driver_id, unique_list_train, False)\n",
    "        if use_pseudo_train_data == True:\n",
    "            print(\"Use_pseudo_train_data\")\n",
    "            X_train, Y_train = add_pseudo_train_data_from_test_set(X_train, Y_train, \n",
    "                                                                   use_roi_picture, pseudo_number)\n",
    "        Y_train = np_utils.to_categorical(Y_train, 10)\n",
    "        \n",
    "        unique_list_valid = [unique_drivers[i] for i in valid_drivers]\n",
    "        X_valid, Y_valid, test_index = copy_selected_drivers(train_files, train_targets, \n",
    "                                                             driver_id, unique_list_valid, True)\n",
    "        \n",
    "        num_fold += 1\n",
    "        print('Start KFold number {} of {}'.format(num_fold, nfolds))\n",
    "        print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "        print('Train drivers:{}, Test drivers:{}'.format(unique_list_train, unique_list_valid))\n",
    "        \n",
    "        model = VGG16_arch(img_rows, img_cols, img_channel, freezing_layer)\n",
    "        \n",
    "        # Initialize weight path    \n",
    "        if not os.path.isdir(os.path.join('cache')):\n",
    "            os.mkdir(os.path.join('cache'))  \n",
    "        \n",
    "        kfold_weights_path = os.path.join('cache', \n",
    "                                          'weights_kfold_augmented_VGG16' + '_' +  str(num_fold) + '.h5')\n",
    "        \n",
    "        # Check if weights already exist \n",
    "        if not os.path.isfile(kfold_weights_path):                \n",
    "            # Intialize Data augmentations            \n",
    "            train_datagen = ImageDataGenerator(zoom_range=0.2, width_shift_range=0.1,\n",
    "                                         height_shift_range=0.1, rotation_range=10)\n",
    "            \n",
    "            # Initialize callbacks\n",
    "            callbacks = [EarlyStopping(monitor='val_loss', patience=4, verbose=0),\n",
    "                         ModelCheckpoint(kfold_weights_path, monitor='val_loss', save_best_only=True, verbose=2),\n",
    "                         ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2), \n",
    "                         MemoryCallback(),\n",
    "                         PlotLosses(), ]\n",
    "\n",
    "            # Train the model\n",
    "            model.fit_generator(train_datagen.flow(X_train, Y_train, batch_size=batch_size, seed=51),\n",
    "                                validation_data=(X_valid, np_utils.to_categorical(Y_valid, 10)), epochs=epochs, use_multiprocessing=False,\n",
    "                                steps_per_epoch=len(X_train)/batch_size, callbacks=callbacks, verbose=0)\n",
    "        \n",
    "        # Load weights\n",
    "        if os.path.isfile(kfold_weights_path):\n",
    "            model.load_weights(kfold_weights_path)\n",
    "        \n",
    "        # Generate validation data predictions\n",
    "        pred_result = model.predict(X_valid, batch_size=batch_size, verbose=0)\n",
    "        \n",
    "        # For computing accuracy_score and confusion_matrix, get the correspond \n",
    "        # probability drive status from pred_result(percentage)\n",
    "        prob_drive_status = []\n",
    "        for x in pred_result:\n",
    "            max_value_index = np.argmax(x)\n",
    "            prob_drive_status.append(max_value_index)\n",
    "        prob_drive_status = np.array(prob_drive_status, dtype=np.uint8)  \n",
    "        \n",
    "        score = accuracy_score(Y_valid, prob_drive_status)\n",
    "        print('Score accuracy_score: ', score)\n",
    "        \n",
    "        array = confusion_matrix(Y_valid, prob_drive_status)\n",
    "        print(array)        \n",
    "        del array\n",
    "\n",
    "        #one-hot handle to Y_valid\n",
    "        Y_valid = np_utils.to_categorical(Y_valid, 10)\n",
    "        score = log_loss(Y_valid, pred_result)\n",
    "        print('Score log_loss: ', score)\n",
    "        \n",
    "        # Store validation score\n",
    "        val_score.append(score)\n",
    "        for i in range(len(test_index)):\n",
    "            val_predictions[test_index[i]] = pred_result[i]\n",
    "        del pred_result\n",
    "    \n",
    "    score_sum=sum(val_score)\n",
    "    print('Validation Average Score ', score_sum/nfolds)\n",
    "\n",
    "    # Converts the dictionary to a list\n",
    "    val_predictions = dict_to_list(val_predictions)\n",
    "    \n",
    "    # Get complete dataset validation score\n",
    "    train_targets = np_utils.to_categorical(train_targets, 10)\n",
    "    score = log_loss(train_targets, val_predictions)\n",
    "    \n",
    "    #Score model\n",
    "    print('(validation score) Final log_loss: {}, nfolds: {} epoch: {}'.format(score, nfolds, epochs))\n",
    "\n",
    "    #return val_predictions, train_files, train_targets, val_score\n",
    "\n",
    "build_VGG16_model(nfolds, epochs, batch_size, img_rows, img_cols, img_channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用训练好的模型预测test数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "def split_list(l, wanted_parts=1):\n",
    "    length = len(l)\n",
    "    return [l[i*length // wanted_parts: (i+1)*length // wanted_parts] for i in range(wanted_parts)]\n",
    "\n",
    "# 获取测试集数据 \n",
    "def load_test_data(part, size=(224, 224)):\n",
    "    \n",
    "    #使用未经ROI处理过的测试集图片\n",
    "    #path = os.path.join('/home/ubuntu/distracted_driver_detection/imgs', 'test', '*.jpg')\n",
    "    \n",
    "    #使用经ROI处理过的测试集图片\n",
    "    path = os.path.join('/home/ubuntu/distracted_driver_detection/imgs', 'test_roi', '*_ROI.jpg')\n",
    "    files = sorted(glob.glob(path))\n",
    "    ch = split_list(files, 10)\n",
    "    \n",
    "    X_test = []\n",
    "    X_test_id = []\n",
    "    x, y = size\n",
    "    for fl in ch[part]:\n",
    "        flbase = os.path.basename(fl)\n",
    "        img = get_im(fl, x, y, 3)\n",
    "        X_test.append(img)\n",
    "        X_test_id.append(flbase)\n",
    "    return X_test, X_test_id\n",
    "\n",
    "# 载入测试数据并进行预处理\n",
    "def read_test_data(part, size=(224,224)):\n",
    "    test_data, test_id = load_test_data(part, size)\n",
    "    #test_data = np.array(test_data, dtype=np.uint8)\n",
    "    test_data = np.array(test_data, dtype=np.float16)\n",
    "    test_data = test_data / 255.0  #zero-center\n",
    "    return test_data, test_id\n",
    "\n",
    "def append_chunk(main, part):\n",
    "    for p in part:\n",
    "        main.append(p)\n",
    "    return main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to compute the result with cache/weights_kfold_augmented_VGG16_1.h5\n",
      "Restore data from pickle......\n",
      "Restore data from pickle......\n",
      "The time of predict test set: 0.006500000000000001 minutes \n",
      "Start to compute the result with cache/weights_kfold_augmented_VGG16_2.h5\n",
      "Restore data from pickle......\n",
      "The time of predict test set: 0.009666666666666665 minutes \n",
      "Start to compute the result with cache/weights_kfold_augmented_VGG16_3.h5\n",
      "Restore data from pickle......\n",
      "The time of predict test set: 0.012833333333333334 minutes \n",
      "Start to compute the result with cache/weights_kfold_augmented_VGG16_4.h5\n",
      "Restore data from pickle......\n",
      "The time of predict test set: 0.01583333333333333 minutes \n",
      "Start to compute the result with cache/weights_kfold_augmented_VGG16_5.h5\n",
      "Restore data from pickle......\n",
      "The time of predict test set: 0.019166666666666665 minutes \n",
      "Start to compute the result with cache/weights_kfold_augmented_VGG16_6.h5\n",
      "Restore data from pickle......\n",
      "The time of predict test set: 0.022333333333333334 minutes \n",
      "Start to compute the result with cache/weights_kfold_augmented_VGG16_7.h5\n",
      "Restore data from pickle......\n",
      "The time of predict test set: 0.025500000000000002 minutes \n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import preprocess_input\n",
    "import time\n",
    "\n",
    "def predict_test_data():\n",
    "    \n",
    "    model = VGG16_arch(img_rows, img_cols, img_channel, freezing_layer)\n",
    "    \n",
    "    num_fold = 0\n",
    "    prediction_list = []\n",
    "    testid_list = []\n",
    "    testid_cache_path = os.path.join('cache','testid_list.h5')\n",
    "    start_time = time.time()\n",
    "    \n",
    "    x = ['cache/weights_kfold_augmented_VGG16_1.h5', 'cache/weights_kfold_augmented_VGG16_2.h5',\n",
    "         'cache/weights_kfold_augmented_VGG16_3.h5', 'cache/weights_kfold_augmented_VGG16_4.h5',\n",
    "         'cache/weights_kfold_augmented_VGG16_5.h5', 'cache/weights_kfold_augmented_VGG16_6.h5',\n",
    "         'cache/weights_kfold_augmented_VGG16_7.h5']\n",
    "\n",
    "    #weights_test_prediction中的key代表使用多少个weights，在weights_test_prediction中key有{0,1,2,3,4}, \n",
    "    #所以表示共使用5个weights, 每个key对应的value，表示weights的名称，比如{0:1}中的key为0，value为1，表示使用\n",
    "    #的weights名为weights_kfold_augmented_VGG16_1.h5\n",
    "    weights_test_prediction = {0:1, 1:2, 2:3, 3:4, 4:5, 5:6, 6:7}\n",
    "    for i in [0,1,2,3,4,5,6]:\n",
    "        \n",
    "        num_fold = weights_test_prediction[i]\n",
    "        weights_path = x[i]\n",
    "        \n",
    "        print(\"Start to compute the result with {}\".format(weights_path))\n",
    "        \n",
    "        if not os.path.isfile(weights_path):\n",
    "            print(weights_path +' File not exists')\n",
    "            return False\n",
    "        model.load_weights(weights_path)\n",
    "        \n",
    "        test_prediction_cache_path = os.path.join('/home/ubuntu/distracted_driver_detection/test_pred_use_pseudo_train_8000', \n",
    "                                                  'test_prediction_VGG16_'+str(num_fold)+'.h5')\n",
    "\n",
    "        if not os.path.isfile(test_prediction_cache_path):\n",
    "            \n",
    "            prediction = []\n",
    "            \n",
    "            # 测试数据分批读入、预处理、预测\n",
    "            for part in range(10):\n",
    "                \n",
    "                test_data_chunk, test_id_chunk = read_test_data(part, (224, 224))\n",
    "                \n",
    "                #test_data_chunk = preprocess_input(test_data_chunk.astype('float16'))\n",
    "                prediction_part = model.predict(test_data_chunk)\n",
    "                prediction = append_chunk(prediction, prediction_part)\n",
    "                \n",
    "                if i == 0:\n",
    "                    testid_list = append_chunk(testid_list, test_id_chunk)\n",
    "                    cache_data(testid_list, testid_cache_path)\n",
    "\n",
    "            cache_data(prediction, test_prediction_cache_path)\n",
    "            prediction_list.append(prediction)  \n",
    "            \n",
    "        elif not os.path.isfile(testid_cache_path):\n",
    "            \n",
    "            for part in range(10):\n",
    "                test_data_chunk, test_id_chunk = read_test_data(part)\n",
    "                if i == 0:\n",
    "                    testid_list = append_chunk(testid_list, test_id_chunk)\n",
    "                    cache_data(testid_list, testid_cache_path)\n",
    "            prediction = restore_data(test_prediction_cache_path)\n",
    "            prediction_list.append(prediction)\n",
    "            \n",
    "        else:\n",
    "            prediction = restore_data(test_prediction_cache_path)\n",
    "            prediction_list.append(prediction)\n",
    "            if i == 0:\n",
    "                testid_list = restore_data(testid_cache_path)\n",
    "                \n",
    "        end_time = time.time()\n",
    "        predict_time_minutes = round(end_time - start_time,2) / 60.0\n",
    "        print(\"The time of predict test set: {} minutes \".format(predict_time_minutes))\n",
    "        \n",
    "    return prediction_list, testid_list\n",
    "\n",
    "prediction_list_vgg16, testid_list_vgg16 = predict_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file to CSV:1.54 seconds\n",
      "Create submit file finished\n"
     ]
    }
   ],
   "source": [
    "#merge_several_folds_mean()函数中的第二个参数，表示在predict_test_data()函数中我所使用的weight数量，\n",
    "#在predict_test_data()中我使用了7个weight, 即['cache/weights_kfold_augmented_VGG16_1.h5', \n",
    "#'cache/weights_kfold_augmented_VGG16_2.h5''cache/weights_kfold_augmented_VGG16_3.h5', \n",
    "#'cache/weights_kfold_augmented_VGG16_4.h5','cache/weights_kfold_augmented_VGG16_5.h5',\n",
    "#'cache/weights_kfold_augmented_VGG16_6.h5','cache/weights_kfold_augmented_VGG16_7.h5']]\n",
    "# 所以此处第二个参数我添加了7\n",
    "result_with10_vgg16 = merge_several_folds_mean(prediction_list_vgg16, 7)\n",
    "result_with10_vgg16 = np.array(result_with10_vgg16)\n",
    "\n",
    "def create_submission(predictions, testid_list, filename, submit_file_path='subm'):\n",
    "    # 为了避免极端值，进行数据裁剪\n",
    "    start = time.time()\n",
    "    predictions = predictions.clip(min=1e-15, max=(1-1e-15))\n",
    "    df = pd.DataFrame(np.array(predictions), columns=['c'+str(i) for i in range(10)])\n",
    "    df.insert(0, 'img', testid_list)\n",
    "    path = os.path.join(submit_file_path, filename)\n",
    "    df.to_csv(path, index=None)\n",
    "    end = time.time()\n",
    "    print(\"file to CSV:{} seconds\".format(round(end - start, 2)))\n",
    "    print('Create submit file finished')\n",
    "\n",
    "create_submission(result_with10_vgg16, testid_list_vgg16, 'submission_10_vgg16_20180830_Use1234567_VGG16.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
